---
title: Meeting transcription overview - Speech service
titleSuffix: Azure AI services
description: You use the meeting transcription feature for meetings. It combines recognition, speaker ID, and diarization to provide transcription of any meeting.
services: cognitive-services
author: eric-urban
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: overview
ms.date: 05/06/2023
ms.author: eur
ms.custom: cogserv-non-critical-speech, ignite-fall-2021, references_regions
---

# What is meeting transcription? (Preview)

Meeting transcription is a [speech to text](speech-to-text.md) solution that provides real-time or asynchronous transcription of any meeting. This feature, which is currently in preview, combines speech recognition, speaker identification, and sentence attribution to determine who said what, and when, in a meeting. 

> [!IMPORTANT]
> The former "conversation transcription" scenario is renamed to "meeting transcription." For example, use `MeetingTranscriber` instead of `ConversationTranscriber`, and use `CreateMeetingAsync` instead of `CreateConversationAsync`. A new "conversation transcription" feature is released without the use of user profiles and voice signatures. For more information, see the [release notes](releasenotes.md?tabs=speech-sdk).

## Key features

You might find the following features of meeting transcription useful:

- **Timestamps:** Each speaker utterance has a timestamp, so that you can easily find when a phrase was said.
- **Readable transcripts:** Transcripts have formatting and punctuation added automatically to ensure the text closely matches what was being said.
- **User profiles:** User profiles are generated by collecting user voice samples and sending them to signature generation.
- **Speaker identification:** Speakers are identified by using user profiles, and a _speaker identifier_ is assigned to each.
- **Multi-speaker diarization:** Determine who said what by synthesizing the audio stream with each speaker identifier.
- **Real-time transcription:** Provide live transcripts of who is saying what, and when, while the meeting is happening.
- **Asynchronous transcription:** Provide transcripts with higher accuracy by using a multichannel audio stream.

> [!NOTE]
> Although meeting transcription doesn't put a limit on the number of speakers in the room, it's optimized for 2-10 speakers per session.

## Get started

See the real-time meeting transcription [quickstart](how-to-use-meeting-transcription.md) to get started.

## Use cases

To make meetings inclusive for everyone, such as participants who are deaf and hard of hearing, it's important to have transcription in real-time. Meeting transcription in real-time mode takes meeting audio and determines who is saying what, allowing all meeting participants to follow the transcript and participate in the meeting, without a delay.

Meeting participants can focus on the meeting and leave note-taking to meeting transcription. Participants can actively engage in the meeting and quickly follow up on next steps, using the transcript instead of taking notes and potentially missing something during the meeting.

## How it works

The following diagram shows a high-level overview of how the feature works.

![Diagram that shows the relationships among different pieces of the meeting transcription solution.](media/scenarios/meeting-transcription-service.png)

## Expected inputs

Meeting transcription uses two types of inputs:

- **Multi-channel audio stream:** For specification and design details, see [Microphone array recommendations](./speech-sdk-microphone.md). 
- **User voice samples:** Meeting transcription needs user profiles in advance of the conversation for speaker identification. Collect audio recordings from each user, and then send the recordings to the [signature generation service](https://aka.ms/cts/signaturegenservice) to validate the audio and generate user profiles.

> [!NOTE]
> Single channel audio configuration for meeting transcription is currently only available in private preview.

User voice samples for voice signatures are required for speaker identification. Speakers who don't have voice samples are recognized as *unidentified*. Unidentified speakers can still be differentiated when the `DifferentiateGuestSpeakers` property is enabled (see the following example). The transcription output then shows speakers as, for example, *Guest_0* and *Guest_1*, instead of recognizing them as pre-enrolled specific speaker names.

```csharp
config.SetProperty("DifferentiateGuestSpeakers", "true");
```

## Real-time vs. asynchronous

The following sections provide more detail about transcription modes you can choose.

### Real-time

Audio data is processed live to return the speaker identifier and transcript. Select this mode if your transcription solution requirement is to provide meeting participants a live transcript view of their ongoing meeting. For example, building an application to make meetings more accessible to participants with hearing loss or deafness is an ideal use case for real-time transcription.

### Asynchronous

Audio data is batch processed to return the speaker identifier and transcript. Select this mode if your transcription solution requirement is to provide higher accuracy, without the live transcript view. For example, if you want to build an application to allow meeting participants to easily catch up on missed meetings, then use the asynchronous transcription mode to get high-accuracy transcription results.

### Real-time plus asynchronous

Audio data is processed live to return the speaker identifier and transcript, and, in addition, requests a high-accuracy transcript through asynchronous processing. Select this mode if your application has a need for real-time transcription, and also requires a higher accuracy transcript for use after the meeting occurred.

## Language support

Currently, meeting transcription supports [all speech to text languages](language-support.md?tabs=stt) in the following regions:â€¯`centralus`, `eastasia`, `eastus`, `westeurope`.

## Next steps

> [!div class="nextstepaction"]
> [Quickstart: Real-time meeting transcription](how-to-use-meeting-transcription.md)
